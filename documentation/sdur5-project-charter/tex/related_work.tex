% Discuss the state-of-the-art with respect to your product. What solutions currently exist, and in what form (academic research, enthusiast prototype, commercially available, etc.)? Include references and citations as necessary using the \textit{cite} command, like this \cite{Rubin2012}. If there are existing solutions, why won't they work for your customer (too expensive, not fast enough, not reliable enough, etc.). This section should occupy 1/2 - 1 full page, and should include at least 5 references to related work. All references should be added to the \textit{.bib} file, fully documented in IEEE format, and should appear in the \textit{references} section at the end of this document (the IEEE citation style will automatically be applied if your reference is properly added to the \textit{.bib} file).

% ProTip: Consider using a citation manager such as Mendeley, Zotero, or EndNote to generate your \textit{.bib} file and maintain documentation references throughout the life cycle of the project.

%Å tip

Our team discovered several different projects that had components that were similar to our UR5 checkers playing robot project. These projects range from applications in academic research to personal robotics projects. Several of these implementations also explore different technology applications such as speech recognition or magnetic sensors. These differences shed light on the various routes that can be taken to best implement the goal of interactively playing checkers through computer vision. Our team hopes to conceive an interactive demonstration of the UR5 robotic arm's capabilities in a similar vein to these related projects.

One of these existing projects we had stumbled across is the Automated Chess Playing Robot Manipulator by Angelkov et al. \cite{Angelkov2015}. These researchers in the Faculty of Computer Science at Goce Delcev University of Stip were able to successfully implement chess rules to a robot arm that could evaluate board position during a match. This project was also very successful in the aspect of computer vision and robot arm precision. From this project, although we are not programming the robot arm to play chess, we might still be able to learn from their computer vision and robotic arm movement implementation. We would prefer to stick to checkers over chess for a public demonstration, since the rules are simpler and it would be more accessible as a demonstration to the public.

Another existing project of the UR5 robotic arm engaging in a game of chess is the Voice Controlled Chess Robot \cite{Ard2020}. This project by William Ard uses speech recognition for translating recognizable vocal commands into the Cartesian coordinates of the chess board. The Python programming language is used to track the board and direct the robotic arm to pick up the chess pieces with a Hand-E gripper and move it across the board. While this project does not involve computer vision, our project may gain inspiration from the algorithms used to coordinate the pieces, but will also integrate machine and computer vision via a camera to  accurately target the chess pieces. This is also because we lack the speech recognition aspect, so our robotic arm must have a source that allows it to understand the state of the board.  

Another project we had seen was a checkers computer vision and move suggestion robot by Alex Thiele \cite{Thiele2015}. This project had successfully implemented robot computer vision and checkers rules. In this project, Thiele implemented a robotic arm to pick and place a checker piece. The robotic arm was equipped with a camera which scanned the board, calculated the new position of the checker piece, and picked and placed the piece in its new position. In our project, we would like to combine checkers, robotics, artificial intelligence, and interactivity to produce a memorable demonstration for prospective students.

The Interactive Robot for Playing Russian Checkers by Kopets et al \cite{Kopets2020}. uses a different type of robotic arm called the 3 Degree of Freedom (3-DOF) Dobot robotic arm in conjunction with Hall sensors. The purpose of the Hall sensors is to avoid using computer vision. The team did not want to use computer vision due to potential complications with light sensitivity and calibration. Instead, the Hall sensors are used to sense if a checker piece is on a specific part of the board. In addition to this, the robotic arm has a limited working space, so the checkers playing board is a custom compact size of 15 cm X 15 cm. This project explores an important aspect of the disadvantages of computer vision. Because our UR5 project will be using computer vision, there will be certain constraints to account for in order to avoid complications such as light sensitivity.  

A more broadly related study is a proposed approach regarding a robot's ability to learn to pick and place objects by Mohammed et al. \cite{Mohammed2021}. The study proposes an effective strategy to pick and place to a new location that focuses on manipulating objects in cluttered environments. The experiments described in this paper details a UR5 co-bot arm, equipped with a Parallel-jaw gripper, which learns to detect the best grasping points of objects through trial and error. The project used Q-network learning method and RGB-D images. Similarly to this study, our project will include pieces that are in a semi-cluttered environment because the checker pieces will be relatively close together. The sensor and camera on the UR5 co-bot arm will need to be able to detect the correct positions and IDs of the checker pieces in order to move them to new positions. In contrast, our project will be using a magnetic gripper, and there will be no variance in the shape and size of the targeted objects that are being picked and placed.  

